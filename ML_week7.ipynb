{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlwPwhfpXuH+z6puh/TuBv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjanaYaragal/Machine-Learning/blob/main/ML_week7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Program 8**"
      ],
      "metadata": {
        "id": "RXN4VsM2IuTK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfeLx8TPEPYJ",
        "outputId": "9db013da-9ac7-47db-d3ab-9f872a439a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.5670869496552929\n",
            "Converged at epoch 73, Loss: 0.0038589548136828845\n",
            "\n",
            "Input\t\tActual Output\t\tPredicted Output\n",
            "[0.66666667 1.        ]\t\t[0.92]\t\t[0.86724023]\n",
            "[0.33333333 0.55555556]\t\t[0.86]\t\t[0.94700395]\n",
            "[1.         0.66666667]\t\t[0.89]\t\t[0.85502024]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Sigmoid activation function and its derivative\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)\n",
        "        self.bias_hidden = np.zeros((1, self.hidden_size))\n",
        "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)\n",
        "        self.bias_output = np.zeros((1, self.output_size))\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Forward propagation\n",
        "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
        "        self.hidden_output = sigmoid(self.hidden_input)\n",
        "        self.output = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        # Backpropagation\n",
        "        # Calculate output layer error and delta\n",
        "        output_error = y - self.output\n",
        "        output_delta = output_error\n",
        "\n",
        "        # Calculate hidden layer error and delta\n",
        "        hidden_error = np.dot(output_delta, self.weights_hidden_output.T)\n",
        "        hidden_delta = hidden_error * sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weights_hidden_output += np.dot(self.hidden_output.T, output_delta) * learning_rate\n",
        "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
        "        self.weights_input_hidden += np.dot(X.T, hidden_delta) * learning_rate\n",
        "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    def train(self, X, y, max_epochs, learning_rate, tolerance=1e-5):\n",
        "        prev_loss = float('inf')\n",
        "        for epoch in range(max_epochs):\n",
        "            # Forward propagation\n",
        "            output = self.forward(X)\n",
        "\n",
        "            # Backpropagation\n",
        "            self.backward(X, y, learning_rate)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = np.mean(np.square(y - output))\n",
        "\n",
        "            # Check for convergence\n",
        "            if abs(prev_loss - loss) < tolerance:\n",
        "                print(f'Converged at epoch {epoch}, Loss: {loss}')\n",
        "                break\n",
        "\n",
        "            prev_loss = loss\n",
        "\n",
        "            # Print loss every 100 epochs\n",
        "            if epoch % 100 == 0:\n",
        "                print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "        # Print input, actual output, and predicted output after training\n",
        "        print(\"\\nInput\\t\\tActual Output\\t\\tPredicted Output\")\n",
        "        for i in range(len(X)):\n",
        "            print(f\"{X[i]}\\t\\t{y[i]}\\t\\t{output[i]}\")\n",
        "\n",
        "# Example usage\n",
        "X = np.array([[0.66666667, 1], [0.33333333, 0.55555556], [1, 0.66666667]])\n",
        "y = np.array([[0.92], [0.86], [0.89]])\n",
        "\n",
        "# Define neural network with 2 input neurons, 2 hidden neurons, and 1 output neuron\n",
        "nn = NeuralNetwork(input_size=2, hidden_size=2, output_size=1)\n",
        "\n",
        "# Train the neural network\n",
        "nn.train(X, y, max_epochs=10000, learning_rate=0.1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FbqveBVzIlM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Program 9a**\n"
      ],
      "metadata": {
        "id": "Kw9Uj9Q0Icrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Data Preparation (read csv file)\n",
        "data = pd.read_csv(\"/train.csv\")  # Assuming \"/train.csv\" is the correct path to your dataset\n",
        "\n",
        "# Step 2: Selecting specific columns\n",
        "columns_to_use = [\"ApplicantIncome\", \"CoapplicantIncome\"]  # Replace with the columns you want to use\n",
        "X = data[columns_to_use]\n",
        "y = data[\"Property_Area\"]  # Replace \"target_column\" with the name of your target column\n",
        "\n",
        "# Step 3: Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
        "\n",
        "# Step 4: Model training and evaluation\n",
        "# Step 5: Create RandomForestClassifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "# Step 6: Fit\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Predict\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Step 8: Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1Ax5nAXSWHS",
        "outputId": "a24cf691-1df4-43dd-d6c8-1b6f7bb5940e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.35772357723577236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrf2rRDlShRc",
        "outputId": "5ee884f5-a1e8-4ae4-ee9f-2ad1fbc59615"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n",
            "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
            "       'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'Loan_Status'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Program** **9b**"
      ],
      "metadata": {
        "id": "rKSUiGCYUytB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Import\n",
        "# Already imported in the previous step\n",
        "\n",
        "# Step 2: Data Preparation (read csv file)\n",
        "data = pd.read_csv(\"/Iris.csv\")  # Replace \"your_dataset.csv\" with the path to your CSV file\n",
        "\n",
        "# Step 3: Separating columns into independent variables and target column\n",
        "columns_to_use = [\"SepalLengthCm\", \"SepalWidthCm\"]  # Replace with the columns you want to use\n",
        "X = data[columns_to_use]\n",
        "y = data[\"PetalLengthCm\"]  # Replace \"target_column\" with the name of your target column\n",
        "\n",
        "\n",
        "# Step 4: Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Model training and evaluation\n",
        "# Step 6: Create AdaBoostClassifier\n",
        "adaboost_classifier = AdaBoostClassifier(n_estimators=50, learning_rate=1)  # Adjust hyperparameters as needed\n",
        "\n",
        "# Step 7: Fit\n",
        "adaboost_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 8: Predict\n",
        "y_pred = adaboost_classifier.predict(X_test)\n",
        "\n",
        "# Step 9: Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "RGQ1-h8dVsPf",
        "outputId": "22fffb3a-8881-4baa-9cda-27a9479756e4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unknown label type: 'continuous'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-db8236fe4d04>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Step 7: Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0madaboost_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Step 8: Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \"\"\"\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SAMME.R\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     ]:\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/Iris.csv\")\n",
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXnY9Wq4VxQ3",
        "outputId": "0b9787ec-b9b1-4a9b-d81c-ab912b2effbb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
            "       'Species'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    }
  ]
}